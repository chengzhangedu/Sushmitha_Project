%pip install --upgrade pip
%pip install openai
%pip install gradio

import os
import openai
import gradio

openai.api_key =  "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"
# Pseudocode 3
questions_list = [
    # "Please tell me your AMT ID so that we can verify your code entered which will help me in giving you rewards later for the inputs you give. Also, kindly provide your zip code.",
    "Have you ever experienced a winter storm? If yes, please describe the most severe winter storm you encountered. When did it occur, and how long did it last?",
    "Did your household experience any infrastructure disruptions during the winter storm, such as power outages, road closures, house damages, or business shutdowns? If so, how did it impact your household?",
    "How did the winter storm affect you or your family members' health, daily life, well-being, finances, or work?",
    "How long did it take for your household to fully recover from the impact of the winter storm, if any? Can you describe what happened during the recovery period?",
    "In your experience, how did you prepare your household for the winter storm? What worked well and what did not work well?",
    "During the winter storm, what assist or aid you would like to have from others, such as organizations, communities, or the government?"
]

status = [0] * len(questions_list)

messages = [
    {"role": "system", "content": "You are a helpful, empathetic, and friendly interviewer who will have meaningful conversations with AMT workers, who will be interviewees. The purpose of the interview is to understand how AMT workers and their households respond to and recover from winter storms. At the beginning of the interview, you need to explain the purpose of the interview to the AMT workers and get affirmation from the interviewee. Ask one question at a time. After getting responses to the questions, please thank the interviewee and conclude the interview."},
    {"role": "system", "name": "example_user", "content": "Interviewee: Hello."},
    {"role": "assistant", "content": "Interviewer: Hello, I am an AI interviewing agent. I would like to understand more about how households respond to extreme weather events. How are you doing today?"},
    {"role": "system", "name": "example_user", "content": "Interviewee: I'm doing good."},
]


# messages.append({"role": "assistant", "content": "Interviewer: Please tell me your AMT ID so that we can verify your code entered which will help me in giving you rewards later for the inputs you give. Also, kindly provide your zip code."})
messages.append({"role": "user", "content": "Interviewee: Thank you."})

# for message in messages:
#     print(f"{message['role']}: {message['content']}")

def check_answer_comprehensive(output, user_input):
    response = openai.Completion.create(
        model="text-davinci-003",
        prompt=f"Does the Interviewee's reply comprehensively answer the question?\n\nQuestion: {output}\nInterviewee: {user_input}\n",
        temperature=0.2,
        max_tokens=100,
    )
    answer_comprehensive = "no"  # Assume the answer is not comprehensive by default
    generated_text = response.choices[0].text.strip().lower()
    return generated_text

def is_question_in_messages(next_question, messages):
    # Check if the next question is already in the conversation history
    response = openai.Completion.create(
      model="text-davinci-003",
      prompt=f"Is the coming question already there in the previous conversation?\n\nQuestion: {next_question}\nPrevious_conversation: {messages}\n",
      temperature=0.2,
      max_tokens=100,)
    response_message = response.choices[0].text.strip().lower()
    # print(response_message,"\n\n")
    if len(response_message) > 0 and "yes" in response_message:
      return True
    return False

def save_conversation_and_status(output, user_input):
    next_question_index = status.index(0)  # Find the index of the next question

    with open("conversation_history.txt", "a") as file:
        file.write(f"Output: {output}\nUser Input: {user_input}\n\n")

def save_status_to_file():
    with open("status.txt", "w") as file:
        for s in status:
            file.write(str(s) + "\n")

def check_question_comprehensive(conversation_history_file, questions_list, question_index):
    with open(conversation_history_file, "r") as file:
        conversation_history = file.read()

    conversation_parts = conversation_history.split("Output:")

    question = "Output:" + conversation_parts[1].strip()  # The output part is treated as the question
    conversation = "Output:".join(conversation_parts[2:])  # The rest of the file is the conversation

    # question = questions_list[question_index]

    response = openai.Completion.create(
        model="text-davinci-003",
        prompt=f"Check if the core question is comprehensively answered from the conversation:\n\nQuestion: {question}\nConversation history: {conversation}\n",
        temperature=0.2,
        max_tokens=100,
    )
    print("Core_question: ",question)
    print("convo:",conversation)
    answer_comprehensive = response.choices[0].text.strip().lower()
    print("Answer comprehensiveness:", answer_comprehensive)
    return answer_comprehensive

output = ""  # Variable to store the current output
previous_output = ""  # Variable to store the previous output
ChatGPT_reply = ""

def CustomChatGPT(user_input):
    global messages, output, previous_output, ChatGPT_reply, follow_up_count

    previous_output = output
    output = ChatGPT_reply

    answer_comprehensive1 = ""

    # Append the user's response to the messages
    messages.append({"role": "user", "content": user_input})

    # Check if the user's response comprehensively answered the previous question
    if ChatGPT_reply:
      answer_comprehensive1 = check_answer_comprehensive(output, user_input)
      print("Ans: ",answer_comprehensive1)

      # Check if the user's response comprehensively answered the previous question
      if len(answer_comprehensive1) > 0 and "yes" in answer_comprehensive1:
          next_question_index = status.index(0)
          next_question = questions_list[next_question_index]
          # print("\npresent_question_index1: ",next_question_index)

          # Check if the next question has already been asked or answered
          if is_question_in_messages(next_question, messages):
              ChatGPT_reply = (
                  f"The below question is already asked/ is answered by you but I am supposed to ask as per the questions given to me.\n\n{next_question}"
              )
          else:
              ChatGPT_reply = f"{next_question}"

          if status[0] == 2:
              status[0] = 1
              with open("conversation_history.txt", "w") as file:
                  file.write("")  # Clear the file if the status is not 2
          elif status[next_question_index - 1] == 2:
              status[next_question_index - 1] = 1
              with open("conversation_history.txt", "w") as file:
                  file.write("")

          status[next_question_index] = 2
          save_conversation_and_status(output, user_input)

          follow_up_count = 0

          print("\nstatus1: ",status)
          # save_status_to_file()

          question_index = status.index(0) - 1
          if question_index >= 0:
              answer_comprehensive = check_question_comprehensive("conversation_history.txt", questions_list, question_index)


          return ChatGPT_reply
          return status

      else:
        if follow_up_count == 0:
          with open("conversation_history.txt", "w") as file:
            file.write("")
        if follow_up_count < 3:
          # If the user's response did not comprehensively answer the previous question, ask a follow-up question
          response = openai.Completion.create(
              model="text-davinci-003",
              prompt=f"Please ask a follow-up question based on the review of interviewee's recent response and previous conversation\n\nReview: {answer_comprehensive1}\nPrevious_conversation: {messages}\n",
              temperature=0.2,
              max_tokens=100,
          )
          follow_up = response.choices[0].text.strip().lower()
          ChatGPT_reply = follow_up
          messages.append({"role": "assistant", "content": follow_up})
          follow_up_count += 1

          save_conversation_and_status(output, user_input)

          return follow_up

        else:
          next_question_index = status.index(0)
          next_question = questions_list[next_question_index]
          # print("\nnext_question_index2: ",next_question_index)

          # Check if the next question has already been asked or answered
          if is_question_in_messages(next_question, messages):
              ChatGPT_reply = (
                  f"The below question is already asked/ is answered by you but I am supposed to ask as per the questions given to me.\n\n{next_question}"
              )
          else:
              ChatGPT_reply = f"{next_question}"

          if "follow-up" not in output:
            if status[0] == 2:
                status[0] = 1
                with open("conversation_history.txt", "w") as file:
                    file.write("")  # Clear the file if the status is not 2
            elif status[next_question_index - 1] == 2:
                status[next_question_index - 1] = 1
                with open("conversation_history.txt", "w") as file:
                    file.write("")

          status[next_question_index] = 2
          save_conversation_and_status(output, user_input)
          # save_status_to_file()

          question_index = status.index(0) - 1
          if question_index >= 0:
              answer_comprehensive = check_question_comprehensive("conversation_history.txt", questions_list, question_index)

          return ChatGPT_reply
          return status

    # Append the combined response to the messages
    messages.append({"role": "assistant", "content": ChatGPT_reply})

    # Get the updated response from the AI model
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo", messages=messages, temperature=0, top_p=1.0
    )
    ChatGPT_reply = response["choices"][0]["message"]["content"]
    messages.append({"role": "assistant", "content": ChatGPT_reply})

    return ChatGPT_reply

demo = gradio.Interface(fn=CustomChatGPT, inputs="text", outputs="text", title="Interview Chatbot")
demo.launch(debug=True)
